{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtpNKfcW8980",
        "outputId": "d4c2fe11-bf1b-4221-f1b3-f9b676d20acd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 48315384.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "training\n",
            "Changing batch size from 16 to 32\n",
            "Epoch: 1, Loss: 2.11828351020813, Training Accuracy: 0.3829, Time: 416.23s\n",
            "Total Epoch Time: 416.23, 32\n",
            "Changing batch size from 32 to 64\n",
            "Epoch: 2, Loss: 1.4790825843811035, Training Accuracy: 0.5768, Time: 425.67s\n",
            "Total Epoch Time: 425.68, 64\n",
            "Changing batch size from 64 to 128\n",
            "Epoch: 3, Loss: 1.3311432600021362, Training Accuracy: 0.6305, Time: 442.26s\n",
            "Total Epoch Time: 442.26, 128\n",
            "Changing batch size from 128 to 16\n",
            "Epoch: 4, Loss: 1.0855016708374023, Training Accuracy: 0.6467, Time: 443.75s\n",
            "Total Epoch Time: 443.75, 16\n",
            "Epoch: 5, Loss: 1.6283986568450928, Training Accuracy: 0.6018, Time: 415.47s\n",
            "Total Epoch Time: 415.47, 16\n",
            "Epoch: 6, Loss: 1.1023520231246948, Training Accuracy: 0.6883, Time: 416.19s\n",
            "Total Epoch Time: 416.19, 16\n",
            "Epoch: 7, Loss: 0.8589321374893188, Training Accuracy: 0.7590, Time: 415.67s\n",
            "Total Epoch Time: 415.68, 16\n",
            "Epoch: 8, Loss: 0.698289692401886, Training Accuracy: 0.8318, Time: 416.52s\n",
            "Total Epoch Time: 416.52, 16\n",
            "Epoch: 9, Loss: 0.23350343108177185, Training Accuracy: 0.9028, Time: 417.05s\n",
            "Total Epoch Time: 417.05, 16\n",
            "Epoch: 10, Loss: 0.12861880660057068, Training Accuracy: 0.9405, Time: 416.10s\n",
            "Total Epoch Time: 416.10, 16\n",
            "Training DONE!!!\n",
            "\n",
            "Testing BEGINS!!\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "k = 5  # Number of previous epochs to use for stopping criterion\n",
        "alpha = 10  # Threshold for stopping criterion\n",
        "s_min = 16  # Minimum batch size\n",
        "s_max = 128  # Maximum batch size\n",
        "target_train_time = 60  # Target training time per epoch in seconds\n",
        "loss_weight = 0.7\n",
        "time_weight = 0.3\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class RandomResizeTransform:\n",
        "    def __init__(self, min_scale=0.5, max_scale=1.5):\n",
        "        self.min_scale = min_scale\n",
        "        self.max_scale = max_scale\n",
        "\n",
        "    def __call__(self, img):\n",
        "        scale = random.uniform(self.min_scale, self.max_scale)\n",
        "        new_size = int(32 * scale)\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(new_size),  # Resize image to new_size\n",
        "            transforms.Pad((32 - new_size) // 2) if new_size < 32 else transforms.CenterCrop(32)  # Pad or crop to maintain 32x32\n",
        "        ])\n",
        "        return transform(img)\n",
        "\n",
        "# Load CIFAR-10 dataset with random resizing transform\n",
        "#transform = transforms.Compose([\n",
        "#    RandomResizeTransform(),\n",
        "#    transforms.ToTensor()\n",
        "#])\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Grayscale(num_output_channels=3),  # Correctly convert grayscale to RGB\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization values for pre-trained models\n",
        "])\n",
        "\n",
        "\n",
        "dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "prev_train_losses = []\n",
        "prev_train_time = []\n",
        "prev_combined_score = 1000\n",
        "training_times = {}\n",
        "def adjust_batch_size(epoch, prev_combined_score, rank, loss, train_time, world_size, batch_size):\n",
        "    tolerance = 10\n",
        "    if rank == 0:\n",
        "        prev_train_losses.append(loss)\n",
        "        prev_train_time.append(train_time)\n",
        "\n",
        "\n",
        "    training_times[batch_size] = train_time\n",
        "\n",
        "    batch_size *= 2\n",
        "    if epoch == 4:\n",
        "        min_key = min(training_times, key=training_times.get)\n",
        "        batch_size = min_key\n",
        "\n",
        "    batch_size = batch_size\n",
        "\n",
        "    return batch_size\n",
        "\n",
        "def train_model():\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    # instantiate the model and transfer it to the GPU\n",
        "    model = models.resnet18()\n",
        "    model.fc = torch.nn.Linear(model.fc.in_features, 10)  # Adjust for CIFAR-10's 10 classes\n",
        "\n",
        "    model = model.to(device)\n",
        "    # wraps the network around distributed package\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    lr = 0.01\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    # Preparing the training data\n",
        "    transforms_train = transforms.Compose([transforms.RandomCrop(32, padding=2),\n",
        "                                           transforms.RandomHorizontalFlip(),\n",
        "                                           transforms.ToTensor(),\n",
        "                                           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=16,\n",
        "                                              shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "\n",
        "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    print(\"training\")\n",
        "    target_loss = 0.5  # Adjust this value based on your requirements\n",
        "\n",
        "    # Training\n",
        "    batch_size = 16\n",
        "    prev_train_losses = []  # Store previous k train losses\n",
        "    prev_combined_score = 1000\n",
        "    for epoch in range(10):\n",
        "        start_epoch_time = time.time()\n",
        "\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        accuracy = 0\n",
        "        total = 0\n",
        "\n",
        "        start_train_time = time.time()\n",
        "        for images, labels in trainloader:\n",
        "            # Move data to the appropriate device\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            for param in model.parameters():\n",
        "              param.grad.data.div_(trainloader.batch_size)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            total += labels.size(0)\n",
        "            _, prediction = outputs.max(1)\n",
        "            accuracy += prediction.eq(labels).sum().item()\n",
        "        end_train_time = time.time()\n",
        "\n",
        "        train_time = end_train_time - start_train_time\n",
        "\n",
        "        # Gather train loss from all processes\n",
        "\n",
        "        # Adjust batch size based on the stopping criterion and training time\n",
        "        if epoch < 4:\n",
        "            new_batch_size = adjust_batch_size(epoch+1, prev_combined_score, train_loss, prev_train_losses, train_time, 1, trainloader.batch_size)\n",
        "\n",
        "        # Limit the batch size to a reasonable range\n",
        "        new_batch_size = max(new_batch_size, 16)  # Minimum batch size\n",
        "        new_batch_size = min(new_batch_size, 128)  # Maximum batch size\n",
        "\n",
        "        if new_batch_size != trainloader.batch_size:\n",
        "            curr = trainloader.batch_size\n",
        "            lr = lr * new_batch_size / curr\n",
        "            print(f\"Changing batch size from {curr} to {new_batch_size}\")\n",
        "            # Re-create the data loaders with the new batch size\n",
        "            trainloader = torch.utils.data.DataLoader(\n",
        "                dataset=dataset, batch_size=new_batch_size, shuffle=False,\n",
        "                num_workers=0, pin_memory=True)\n",
        "\n",
        "        print(f\"Epoch: {epoch + 1}, Loss: {loss.item()}, Training Accuracy: {accuracy / total:.4f}, \"\n",
        "                  f\"Time: {end_train_time - start_train_time:.2f}s\")\n",
        "\n",
        "        end_epoch_time = time.time()\n",
        "\n",
        "        print(f\"Total Epoch Time: {end_epoch_time - start_epoch_time:.2f}, {trainloader.batch_size}\")\n",
        "\n",
        "    print(\"Training DONE!!!\")\n",
        "    print()\n",
        "    print('Testing BEGINS!!')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def run_train_model(train_func, world_size):\n",
        "\n",
        "    # this is responsible for spawning 'nprocs' number of processes of the train_func function with the given\n",
        "    # arguments as 'args'\n",
        "    train_func()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # since this example shows a single process per GPU, the number of processes is simply replaced with the\n",
        "    # number of GPUs available for training.\n",
        "    n_gpus = torch.cuda.device_count()\n",
        "    run_train_model(train_model, n_gpus)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "# packages for distributed training\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "torch.backends.cudnn.enabled = False\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "import random"
      ],
      "metadata": {
        "id": "FJIGGyE59jn0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}